{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Y-7CWKkxe900"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RBN-fzeWeqpL"
      },
      "outputs": [],
      "source": [
        "customer_df = pd.read_csv('customer_features.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "_STgguHNe-_L",
        "outputId": "621d1449-311e-4cee-bee5-57cbc5af9811"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   customer_id  total_spend  total_transactions  avg_order_value  \\\n",
              "0            1    228156.76                  19     12008.250526   \n",
              "1            2     14659.49                   1     14659.490000   \n",
              "2            3     76364.73                   5     15272.946000   \n",
              "3            4     64789.63                   4     16197.407500   \n",
              "4            5    218675.35                  13     16821.180769   \n",
              "\n",
              "  first_transaction_date last_transaction_date  recency_days  tenure_days  \\\n",
              "0             2020-04-30            2021-08-02          1612         2071   \n",
              "1             2022-10-23            2022-10-23          1165         1165   \n",
              "2             2022-07-13            2022-10-23          1165         1267   \n",
              "3             2019-09-24            2019-11-23          2230         2290   \n",
              "4             2022-08-15            2023-07-14           901         1234   \n",
              "\n",
              "   spend_last_30d  tx_last_30d  ...  tx_last_60d  spend_last_90d  tx_last_90d  \\\n",
              "0             0.0          0.0  ...          0.0             0.0          0.0   \n",
              "1             0.0          0.0  ...          0.0             0.0          0.0   \n",
              "2             0.0          0.0  ...          0.0             0.0          0.0   \n",
              "3             0.0          0.0  ...          0.0             0.0          0.0   \n",
              "4             0.0          0.0  ...          0.0             0.0          0.0   \n",
              "\n",
              "   unique_products  unique_categories  dominant_category segment_id  \\\n",
              "0             53.0                8.0               Home        4.0   \n",
              "1              4.0                3.0             Beauty        4.0   \n",
              "2             15.0                7.0            Fashion        4.0   \n",
              "3             12.0                7.0            Fashion        3.0   \n",
              "4             43.0                8.0        Electronics        4.0   \n",
              "\n",
              "  loyalty_status total_loyalty_points  is_cold_start  \n",
              "0           Gold                 2347              0  \n",
              "1         Bronze                  166              1  \n",
              "2         Bronze                  763              0  \n",
              "3         Silver                  663              0  \n",
              "4         Silver                 2186              0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59f3adac-54ed-4cba-b58e-2373ef31fb89\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>total_spend</th>\n",
              "      <th>total_transactions</th>\n",
              "      <th>avg_order_value</th>\n",
              "      <th>first_transaction_date</th>\n",
              "      <th>last_transaction_date</th>\n",
              "      <th>recency_days</th>\n",
              "      <th>tenure_days</th>\n",
              "      <th>spend_last_30d</th>\n",
              "      <th>tx_last_30d</th>\n",
              "      <th>...</th>\n",
              "      <th>tx_last_60d</th>\n",
              "      <th>spend_last_90d</th>\n",
              "      <th>tx_last_90d</th>\n",
              "      <th>unique_products</th>\n",
              "      <th>unique_categories</th>\n",
              "      <th>dominant_category</th>\n",
              "      <th>segment_id</th>\n",
              "      <th>loyalty_status</th>\n",
              "      <th>total_loyalty_points</th>\n",
              "      <th>is_cold_start</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>228156.76</td>\n",
              "      <td>19</td>\n",
              "      <td>12008.250526</td>\n",
              "      <td>2020-04-30</td>\n",
              "      <td>2021-08-02</td>\n",
              "      <td>1612</td>\n",
              "      <td>2071</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Home</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Gold</td>\n",
              "      <td>2347</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>14659.49</td>\n",
              "      <td>1</td>\n",
              "      <td>14659.490000</td>\n",
              "      <td>2022-10-23</td>\n",
              "      <td>2022-10-23</td>\n",
              "      <td>1165</td>\n",
              "      <td>1165</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Bronze</td>\n",
              "      <td>166</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>76364.73</td>\n",
              "      <td>5</td>\n",
              "      <td>15272.946000</td>\n",
              "      <td>2022-07-13</td>\n",
              "      <td>2022-10-23</td>\n",
              "      <td>1165</td>\n",
              "      <td>1267</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Fashion</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Bronze</td>\n",
              "      <td>763</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>64789.63</td>\n",
              "      <td>4</td>\n",
              "      <td>16197.407500</td>\n",
              "      <td>2019-09-24</td>\n",
              "      <td>2019-11-23</td>\n",
              "      <td>2230</td>\n",
              "      <td>2290</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Fashion</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Silver</td>\n",
              "      <td>663</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>218675.35</td>\n",
              "      <td>13</td>\n",
              "      <td>16821.180769</td>\n",
              "      <td>2022-08-15</td>\n",
              "      <td>2023-07-14</td>\n",
              "      <td>901</td>\n",
              "      <td>1234</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Silver</td>\n",
              "      <td>2186</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59f3adac-54ed-4cba-b58e-2373ef31fb89')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-59f3adac-54ed-4cba-b58e-2373ef31fb89 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-59f3adac-54ed-4cba-b58e-2373ef31fb89');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "customer_df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqYsIZvWf8gO",
        "outputId": "515b6661-3155-4c95-9459-79e5330a03e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['customer_id', 'total_spend', 'total_transactions', 'avg_order_value',\n",
              "       'first_transaction_date', 'last_transaction_date', 'recency_days',\n",
              "       'tenure_days', 'spend_last_30d', 'tx_last_30d', 'spend_last_60d',\n",
              "       'tx_last_60d', 'spend_last_90d', 'tx_last_90d', 'unique_products',\n",
              "       'unique_categories', 'dominant_category', 'segment_id',\n",
              "       'loyalty_status', 'total_loyalty_points', 'is_cold_start'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Check if xgboost is available, otherwise fall back to ExtraTrees\n",
        "try:\n",
        "    from xgboost import XGBRegressor\n",
        "    xgb_available = True\n",
        "except ImportError:\n",
        "    xgb_available = False\n",
        "    print(\"XGBoost not found. Using ExtraTreesRegressor instead.\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 1. SETUP & TARGET CREATION\n",
        "# -----------------------------------------------------------------------------\n",
        "# NOTE: Using existing 'customer_df' from memory as requested.\n",
        "# If running this standalone for testing without the dataframe in memory,\n",
        "# uncomment the block below to simulate the schema structure (strictly for testing flow).\n",
        "# -----------------------------------------------------------------------------\n",
        "# if 'customer_df' not in locals():\n",
        "#     raise ValueError(\"customer_df is not defined in memory.\")\n",
        "\n",
        "TARGET = \"spend_next_30d\"\n",
        "\n",
        "# Ensure Target Exists (Safety Check)\n",
        "if TARGET not in customer_df.columns:\n",
        "    # In a real scenario, this should be derived from future transaction logs.\n",
        "    # For this pipeline to run if the column is missing in the provided df,\n",
        "    # we simulate it based on 'spend_last_30d' + noise to demonstrate functionality.\n",
        "    # This is STRICTLY a fallback to ensure the code below is runnable.\n",
        "    print(f\"Warning: '{TARGET}' not found. Deriving mock target for demonstration.\")\n",
        "    np.random.seed(42)\n",
        "    customer_df[TARGET] = customer_df['spend_last_30d'] * np.random.normal(1.0, 0.2, len(customer_df))\n",
        "    customer_df[TARGET] = customer_df[TARGET].clip(lower=0) # Spend cannot be negative\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 2. FEATURE ENGINEERING & LEAKAGE PREVENTION\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Columns to explicitly drop to prevent leakage or ID/Date issues\n",
        "cols_to_drop = [\n",
        "    'customer_id',\n",
        "    TARGET,\n",
        "    'first_transaction_date',\n",
        "    'last_transaction_date'\n",
        "]\n",
        "\n",
        "# Define Feature Matrix (X) and Target Vector (y)\n",
        "X = customer_df.drop(columns=[c for c in cols_to_drop if c in customer_df.columns], errors='ignore')\n",
        "y = customer_df[TARGET]\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 3. PREPROCESSING PIPELINE\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Automatically detect column types\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "print(f\"Numerical Features ({len(numeric_features)}): {numeric_features}\")\n",
        "print(f\"Categorical Features ({len(categorical_features)}): {categorical_features}\")\n",
        "\n",
        "# Numerical Pipeline: Impute Median -> Standard Scale\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Categorical Pipeline: Impute Most Frequent -> OneHot Encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "# Combine into ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='drop' # Drop any columns not explicitly handled\n",
        ")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 4. TRAIN / VALIDATION SPLIT\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
        "print(f\"Validation set shape: {X_val.shape}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 5. MODEL DEFINITIONS\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "models = {\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "}\n",
        "\n",
        "if xgb_available:\n",
        "    models[\"XGBoost\"] = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "else:\n",
        "    models[\"Extra Trees\"] = ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 6. EVALUATION FUNCTION\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def evaluate_model(name, model, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Predicts and evaluates a model on validation data.\n",
        "    Returns a dictionary of metrics.\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "    print(f\"\\n--- {name} Results ---\")\n",
        "    print(f\"MAE:  {mae:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"R¬≤:   {r2:.4f}\")\n",
        "\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2, 'Model': model}\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 7. TRAINING & COMPARISON LOOP\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "results = {}\n",
        "best_model_name = None\n",
        "best_model_score = -float('inf') # Maximizing R2\n",
        "\n",
        "print(\"\\nüöÄ Starting Model Training...\")\n",
        "\n",
        "for name, model_instance in models.items():\n",
        "    # Create a full pipeline for the specific model\n",
        "    clf = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', model_instance)\n",
        "    ])\n",
        "\n",
        "    # Train\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    metrics = evaluate_model(name, clf, X_val, y_val)\n",
        "    results[name] = metrics\n",
        "\n",
        "    # Model Selection Logic (Based on R2)\n",
        "    if metrics['R2'] > best_model_score:\n",
        "        best_model_score = metrics['R2']\n",
        "        best_model_name = name\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 8. BEST MODEL SELECTION & EXPLANATION\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(f\"üèÜ BEST PERFORMING MODEL: {best_model_name}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "best_pipeline = results[best_model_name]['Model']\n",
        "\n",
        "print(f\"\\nWhy {best_model_name} likely won:\")\n",
        "if \"Boosting\" in best_model_name or \"XGBoost\" in best_model_name:\n",
        "    print(\"- Boosting algorithms effectively reduce bias by sequentially correcting errors.\")\n",
        "    print(\"- They handle non-linear relationships well and are robust to outliers in spend data.\")\n",
        "elif \"Forest\" in best_model_name or \"Trees\" in best_model_name:\n",
        "    print(\"- Ensemble tree methods reduce variance through bagging.\")\n",
        "    print(\"- They are very effective at capturing complex interactions between recency and frequency features.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khgc02sQfAXb",
        "outputId": "e0551e12-5404-4875-9310-a20035ec0756"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 'spend_next_30d' not found. Deriving mock target for demonstration.\n",
            "Numerical Features (15): ['total_spend', 'total_transactions', 'avg_order_value', 'recency_days', 'tenure_days', 'spend_last_30d', 'tx_last_30d', 'spend_last_60d', 'tx_last_60d', 'spend_last_90d', 'tx_last_90d', 'unique_products', 'unique_categories', 'total_loyalty_points', 'is_cold_start']\n",
            "Categorical Features (3): ['dominant_category', 'segment_id', 'loyalty_status']\n",
            "\n",
            "Training set shape: (16000, 18)\n",
            "Validation set shape: (4000, 18)\n",
            "\n",
            "üöÄ Starting Model Training...\n",
            "\n",
            "--- Gradient Boosting Results ---\n",
            "MAE:  230.3375\n",
            "RMSE: 1178.1817\n",
            "R¬≤:   0.9627\n",
            "\n",
            "--- Random Forest Results ---\n",
            "MAE:  222.7946\n",
            "RMSE: 1178.1015\n",
            "R¬≤:   0.9627\n",
            "\n",
            "--- XGBoost Results ---\n",
            "MAE:  293.6344\n",
            "RMSE: 1545.3224\n",
            "R¬≤:   0.9358\n",
            "\n",
            "========================================\n",
            "üèÜ BEST PERFORMING MODEL: Random Forest\n",
            "========================================\n",
            "\n",
            "Why Random Forest likely won:\n",
            "- Ensemble tree methods reduce variance through bagging.\n",
            "- They are very effective at capturing complex interactions between recency and frequency features.\n",
            "\n",
            "‚úÖ Model pipeline saved to 'best_customer_spend_model.joblib'\n",
            "\n",
            "üîç Example Inference (First 2 Validation Rows):\n",
            "Actual:    [0. 0.]\n",
            "Predicted: [0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# 9. SAVE ARTIFACTS\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "filename = 'best_customer_spend_model.joblib'\n",
        "joblib.dump(best_pipeline, filename)\n",
        "print(f\"\\n‚úÖ Model pipeline saved to '{filename}'\")\n",
        "\n",
        "# Example Inference\n",
        "print(\"\\nüîç Example Inference (First 2 Validation Rows):\")\n",
        "sample_data = X_val.iloc[:2]\n",
        "predictions = best_pipeline.predict(sample_data)\n",
        "print(f\"Actual:    {y_val.iloc[:2].values}\")\n",
        "print(f\"Predicted: {predictions}\")"
      ],
      "metadata": {
        "id": "TsHOtgpsiKF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# 9. SAVE ARTIFACTS (USING PICKLE)\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "import pickle\n",
        "\n",
        "filename = \"best_customer_spend_model.pkl\"\n",
        "\n",
        "with open(filename, \"wb\") as f:\n",
        "    pickle.dump(best_pipeline, f)\n",
        "\n",
        "print(f\"\\n‚úÖ Model pipeline saved to '{filename}'\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Example Inference\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\nüîç Example Inference (First 2 Validation Rows):\")\n",
        "\n",
        "sample_data = X_val.iloc[:2]\n",
        "predictions = best_pipeline.predict(sample_data)\n",
        "\n",
        "print(f\"Actual:    {y_val.iloc[:2].values}\")\n",
        "print(f\"Predicted: {predictions}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wckbQ02FjGT4",
        "outputId": "79a63d2b-e43a-4d7e-c3ac-98e8b35b6be1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Model pipeline saved to 'best_customer_spend_model.pkl'\n",
            "\n",
            "üîç Example Inference (First 2 Validation Rows):\n",
            "Actual:    [0. 0.]\n",
            "Predicted: [0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f7wDaawjjGj1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}